from google.colab import drive
drive.mount('/content/drive')

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_path = "/content/drive/MyDrive/core_project"
img_dir = f"{project_path}/core_images"
csv_dir = f"{project_path}/mscl_data"

!ls {project_path}
!ls {img_dir} | head
!ls {csv_dir} | head

!pip install torch torchvision pandas scikit-learn matplotlib Pillow tqdm

import pandas as pd
import numpy as np
import glob

# ëª¨ë“  CSV ë¡œë“œ
csv_files = glob.glob(f"{csv_dir}/*.csv")
print(f"ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ ë¡œë“œ")

dataframes = []
for file in csv_files:
    df = pd.read_csv(file)
    core_id = file.split("/")[-1].replace(".csv", "")
    df['core_id'] = core_id
    dataframes.append(df)

# ì „ì²´ í•©ì¹˜ê¸°
full_df = pd.concat(dataframes, ignore_index=True)

# NaN ì²˜ë¦¬ (ë‹¤í•­ì‹ ë³´ê°„ + ì „í›„ê°’ ë³´ê°„)
columns_to_fix = ["pwave_vel", "density", "mag_sus"]
for col in columns_to_fix:
    if full_df[col].isna().sum() > 0:
        full_df[col] = full_df[col].interpolate(method="polynomial", order=2)
        full_df[col] = full_df[col].fillna(method="ffill").fillna(method="bfill")

print(full_df.head())

from PIL import Image
import os

# ë§¤í•‘ í‚¤: core_id + section â†’ ì´ë¯¸ì§€ íŒŒì¼ëª…
# ì˜ˆì‹œ: 2019_643_FA_GC01_01.tif â†’ core_id=2019_643_FA_GC01, section=01
# full_dfì—ì„œ core_idì™€ depth ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì´ë¯¸ì§€ ë§¤ì¹­

image_files = [f for f in os.listdir(img_dir) if f.endswith('.tif')]
print(f"ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(image_files)}")

# ì´ë¯¸ì§€ íŒŒì¼ â†’ core_id ì»¬ëŸ¼ê³¼ ë§¤í•‘
image_map = {}
for img in image_files:
    parts = img.replace(".tif", "").split("_")
    core_id = "_".join(parts[:4])  # ì˜ˆ: 2019_643_FA_GC01
    image_map.setdefault(core_id, []).append(img)

# ê° core_idì˜ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ í™•ì¸
for k, v in list(image_map.items())[:3]:
    print(f"{k}: {v[:3]}")

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

available_core_ids = set(image_map.keys())
full_df = full_df[full_df['core_id'].isin(available_core_ids)].reset_index(drop=True)

# ==========================================================================
# ìˆ˜ì • 1 : csv íŒŒì¼ê³¼ ì´ë¯¸ì§€ íŒŒì¼ì´ ë§¤ì¹­ë˜ì§€ ì•Šì€(í•œ ìª½ì— ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°) ì œì™¸ì‹œí‚´
# ==========================================================================
# core_idë¥¼ í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€ê²½ (ê²½ë¡œ ì œê±°)
full_df['core_id'] = full_df['core_id'].apply(lambda x: os.path.basename(x).replace(".csv", ""))

# 1. ê³µí†µëœ core_idë§Œ ì¶”ì¶œ
csv_core_ids = set(full_df['core_id'].unique())
image_core_ids = set(image_map.keys())
common_core_ids = csv_core_ids & image_core_ids

# 2. ì œì™¸ëœ ê²ƒë“¤ í™•ì¸
csv_only = csv_core_ids - image_core_ids
image_only = image_core_ids - csv_core_ids

print(f"\nâŒ ì œì™¸ëœ core_id (CSVëŠ” ìˆì§€ë§Œ ì´ë¯¸ì§€ ì—†ìŒ): {sorted(list(csv_only))}")
print(f"âŒ ì œì™¸ëœ core_id (ì´ë¯¸ì§€ëŠ” ìˆì§€ë§Œ CSV ì—†ìŒ): {sorted(list(image_only))}")

# 3. ê³µí†µëœ core_idë§Œ ìœ ì§€
filtered_df = full_df[full_df['core_id'].isin(common_core_ids)].reset_index(drop=True)
print(f"âœ… ìµœì¢… usable ë°ì´í„° ìˆ˜: {len(filtered_df)}")

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# ============================================================
# ìˆ˜ì • 2 : ê°™ì€ ì½”ì–´ ID ì´ë¯¸ì§€ë¥¼ ë³‘í•©í•˜ê³  1cm(200í”½ì…€) ë‹¨ìœ„ë¡œ ë¶„í• í•¨.
# ============================================================
class CoreDataset(Dataset):
    def __init__(self, dataframe, img_dir, transform=None, pixels_per_cm=200):
        self.dataframe = dataframe
        self.img_dir = img_dir
        self.transform = transform
        self.pixels_per_cm = pixels_per_cm
        self.samples = []

        for core_id in dataframe['core_id'].unique():
            df_core = dataframe[dataframe['core_id'] == core_id].reset_index(drop=True)
            img_list = image_map.get(core_id, [])
            if not img_list:
                continue

            '''
            ì´ë¯¸ì§€ë¥¼ 200 í”½ì…€ ë‹¨ìœ„(1cm = 200í”½ì…€)ë¡œ ì˜ë¼ì„œ csvì˜ ë‹¨ìœ„ì™€ ì¼ì¹˜ì‹œí‚´
            ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ê°œë¡œ ë‚˜ëˆ ì ¸ ì €ì¥ë˜ì–´ ìˆìŒ. ()..._01.tif, ..._02.tifì™€ ê°™ì´ ì €ì¥ë˜ì–´ ìˆìŒ)
            ë”°ë¼ì„œ ê°™ì€ ì½”ì–´ IDë¥¼ ê°€ì§€ê³  ìˆë‹¤ë©´ ì´ë¯¸ì§€ë¥¼ í•©ì³ 200 í”½ì…€ ë‹¨ìœ„ë¡œ ìë¦„
            '''
            img_slices = []
            for img_name in sorted(img_list):  # ì´ë¯¸ì§€ ìˆœì„œ ë³´ì¥
                img_path = os.path.join(img_dir, img_name)
                try:
                    with Image.open(img_path) as img:
                        width, height = img.size
                        num_slices = height // self.pixels_per_cm
                        for i in range(num_slices):
                            img_slices.append((img_path, i))
                except:
                    continue

            usable = min(len(img_slices), len(df_core))
            for i in range(usable):
                self.samples.append({
                    "img_path": img_slices[i][0],
                    "slice_idx": img_slices[i][1],
                    "row": df_core.iloc[i]
                })

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample = self.samples[idx]
        row = sample["row"]
        img_path = sample["img_path"]
        slice_idx = sample["slice_idx"]

        with Image.open(img_path) as img:
            x0, y0 = 0, slice_idx * self.pixels_per_cm
            x1, y1 = img.width, (slice_idx + 1) * self.pixels_per_cm
            crop = img.crop((x0, y0, x1, y1)).convert("RGB")

        if self.transform:
            crop = self.transform(crop)

        labels = torch.tensor([row["density"], row["pwave_vel"], row["mag_sus"]], dtype=torch.float32)

        return crop, labels

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

from sklearn.model_selection import train_test_split

# âœ… ê³ ìœ  core_id ê¸°ì¤€ìœ¼ë¡œ ë¨¼ì € ë¶„í• 
core_ids = filtered_df["core_id"].unique()
train_ids, temp_ids = train_test_split(core_ids, test_size=0.3, random_state=42)
val_ids, test_ids = train_test_split(temp_ids, test_size=0.33, random_state=42)  # 0.3 * 0.33 â‰ˆ 0.10

# âœ… í•´ë‹¹ IDë“¤ë§Œ í•„í„°ë§
train_df = filtered_df[filtered_df["core_id"].isin(train_ids)].reset_index(drop=True)
val_df   = filtered_df[filtered_df["core_id"].isin(val_ids)].reset_index(drop=True)
test_df  = filtered_df[filtered_df["core_id"].isin(test_ids)].reset_index(drop=True)

# âœ… ë‹¤ì‹œ Dataset ë° DataLoader ìƒì„±
train_ds = CoreDataset(train_df, img_dir, transform)
val_ds   = CoreDataset(val_df, img_dir, transform)
test_ds  = CoreDataset(test_df, img_dir, transform)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_ds, batch_size=32)
test_loader  = DataLoader(test_ds, batch_size=32)

import torch
import torch.nn as nn
from torchvision import models
from tqdm import tqdm

# âœ… ì‚¬ì „ í•™ìŠµëœ ResNet18 + íšŒê·€ í—¤ë“œ
model = models.resnet18(pretrained=True)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 3)  # ì¶œë ¥: density, pwave_vel, mag_sus

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# ì†ì‹¤í•¨ìˆ˜ ë° ìµœì í™” ë„êµ¬
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# ìŠ¤ì¼€ì¼ ì •ê·œí™” (StandardScaler ê¸°ì¤€) â¤ HRNetê³¼ ë™ì¼í•œ ë‹¨ìœ„ ì •ë ¬
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

# í•™ìŠµìš© ë¼ë²¨ ìŠ¤ì¼€ì¼ë§ (fit)
all_labels = train_df[["density", "pwave_vel", "mag_sus"]].values
scaler.fit(all_labels)

# =====================
# ëª¨ë¸ í•™ìŠµ ë¶€ë¶„
# =====================
import torch
import torch.nn as nn
from torchvision import models
from tqdm import tqdm

model = models.resnet18(pretrained=True)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 3)  # density, pwave_vel, mag_sus

model = model.cuda()

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

num_epochs = 15
train_losses, val_losses = [], []

for epoch in range(num_epochs):
    model.train()
    train_loss = 0

    print(f"\nğŸ” Epoch [{epoch+1}/{num_epochs}]")
    train_bar = tqdm(train_loader, desc="ğŸŸ¢ Training", leave=False)

    for images, labels in train_bar:
        images, labels = images.cuda(), labels.cuda()
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_bar.set_postfix(loss=loss.item())

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import numpy as np
import torch

# ëª¨ë¸ í‰ê°€ ëª¨ë“œ
model.eval()
y_true, y_pred = [], []

# ğŸ”„ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)

        y_pred.append(outputs.cpu().numpy())   # ì˜ˆì¸¡ê°’ (ì •ê·œí™”ëœ ìƒíƒœ)
        y_true.append(labels.numpy())          # ì‹¤ì œê°’ (ì •ê·œí™”ëœ ìƒíƒœ)

# ë°°ì—´ ì •ë¦¬
y_true = np.vstack(y_true)
y_pred = np.vstack(y_pred)

# ğŸ” ì—­ì •ê·œí™” (ì‹¤ì œ ë‹¨ìœ„ë¡œ í™˜ì‚°)
y_true_denorm = scaler.inverse_transform(y_true)
y_pred_denorm = scaler.inverse_transform(y_pred)

# ğŸ“Œ ë¬¼ì„± ì´ë¦„
features = ['Density', 'P-wave Velocity', 'Magnetic Susceptibility']

# ğŸ“Š ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
print("\nğŸ“Š [ì‹¤ì œ ë‹¨ìœ„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•œ ì„±ëŠ¥ ì§€í‘œ]")
for i, name in enumerate(features):
    rmse = np.sqrt(mean_squared_error(y_true_denorm[:, i], y_pred_denorm[:, i]))
    mae = mean_absolute_error(y_true_denorm[:, i], y_pred_denorm[:, i])
    r2 = r2_score(y_true_denorm[:, i], y_pred_denorm[:, i])
    print(f"\nğŸ“Œ {name}")
    print(f"  RMSE : {rmse:.4f}")
    print(f"  MAE  : {mae:.4f}")
    print(f"  RÂ²   : {r2:.4f}")

# ğŸ“ˆ êº¾ì€ì„  ê·¸ë˜í”„ (ì˜ˆì¸¡ vs ì‹¤ì œê°’ ë¹„êµ)
plt.figure(figsize=(18, 5))
for i, name in enumerate(features):
    plt.subplot(1, 3, i + 1)
    plt.plot(y_true_denorm[:, i], label="True", color='blue', marker='o', markersize=2, linewidth=1)
    plt.plot(y_pred_denorm[:, i], label="Pred", color='red', linestyle='--', marker='x', markersize=2, linewidth=1)
    plt.title(f"{name} (Slice 0 ~ {len(y_true) - 1})")
    plt.xlabel("Slice Index (1cm units)")
    plt.ylabel(name)
    plt.grid(True)
    plt.legend()

plt.tight_layout()
plt.show()

import pandas as pd
import os

# ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥
results_df = pd.DataFrame({
    "density": y_pred_denorm[:, 0],
    "pwave_vel": y_pred_denorm[:, 1],
    "mag_sus": y_pred_denorm[:, 2]
})
csv_save_path = "/content/drive/MyDrive/core_project/pred_resnet18_results.csv"
results_df.to_csv(csv_save_path, index=False)
print(f"âœ… ì˜ˆì¸¡ CSV ì €ì¥ ì™„ë£Œ: {csv_save_path}")

# ì˜ˆì¸¡ vs ì‹¤ì œ ì‹œê°í™” (100 ìŠ¬ë¼ì´ìŠ¤ ë‹¨ìœ„ ì €ì¥)
def visualize_prediction_vs_truth_by_chunks(csv_path, output_dir, chunk_size=100, core_id='ResNet18_Core'):
    df = pd.read_csv(csv_path)
    os.makedirs(output_dir, exist_ok=True)

    prop_names = ['density', 'pwave_vel', 'mag_sus']
    total_len = len(df)

    for start in range(0, total_len, chunk_size):
        end = min(start + chunk_size, total_len)
        x = list(range(start, end))

        fig, axes = plt.subplots(1, 3, figsize=(18, 5), constrained_layout=True)

        for i, prop in enumerate(prop_names):
            y_true = df[f"true_{prop}"].iloc[start:end]
            y_pred = df[f"pred_{prop}"].iloc[start:end]

            axes[i].plot(x, y_true, 'o-', color='blue', label='True')
            axes[i].plot(x, y_pred, 'x--', color='red', label='Pred')
            axes[i].set_title(f"{prop.capitalize()} (Slice {start} ~ {end})")
            axes[i].set_xlabel("Slice Index (1cm units)")
            axes[i].set_ylabel(prop)
            axes[i].grid(True)
            axes[i].legend()

        save_path = os.path.join(output_dir, f"{core_id}_slice_{start}_{end}.png")
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"âœ… ì €ì¥: {save_path}")
